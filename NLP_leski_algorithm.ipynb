{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdddd4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import wikipediaapi\n",
    "import wikipedia\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24d65f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = \"This plant requires sunlight and watering every morning.\"\n",
    "target = 'plant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f65c6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_wnlemma(sent, stop_rm = False):\n",
    "    sentence = ''\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(sent)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word.isalpha()]\n",
    "    words = [word.lower() for word in words]\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    #sentence = ' '.join(words)  # Use 'join' to concatenate words with spaces\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28c4c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sent = (preprocess_wnlemma(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6765d63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plant', 'requires', 'sunlight', 'watering', 'every', 'morning']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f65890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WIKIte(title):\n",
    "    wiki = wikipedia.page(title)\n",
    "    text = wiki.content\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dba9d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def WIKI_main(title, lang=\"en\"):\n",
    "    try:\n",
    "        wikipedia.set_lang(lang)\n",
    "        wiki_page = wikipedia.page(title, auto_suggest=False, redirect=True)\n",
    "        return wiki_page.summary\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return f\"Disambiguation page! Options: {e.options}\"\n",
    "    except wikipedia.exceptions.HTTPTimeoutError:\n",
    "        return \"Timeout error. Please try again later.\"\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        return f\"No Wikipedia page found for {title}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "208910ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A chemical plant is an industrial process plant that manufactures (or otherwise processes) chemicals, usually on a large scale. The general objective of a chemical plant is to create new material wealth via the chemical or biological transformation and or separation of materials. Chemical plants use specialized equipment, units, and technology in the manufacturing process.  Other kinds of plants, such as polymer, pharmaceutical, food, and some beverage production facilities, power plants, oil refineries or other refineries, natural gas processing and biochemical plants, water and wastewater treatment, and pollution control equipment use many technologies that have similarities to chemical plant technology such as fluid systems and chemical reactor systems.  Some would consider an oil refinery or a pharmaceutical or polymer manufacturer to be effectively a chemical plant.\\nPetrochemical plants (plants using chemicals from petroleum as a raw material or  feedstock) are usually located adjacent to an oil refinery to minimize transportation costs for the feedstocks produced by the refinery. Speciality chemical and fine chemical plants are usually much smaller and not as sensitive to location. Tools have been developed for converting a base project cost from one geographic location to another.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = WIKI_main('chemical plant')\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ea27582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_len_disambiguation_options(title):\n",
    "    try:\n",
    "        wiki = wikipedia.page(title)\n",
    "        return []\n",
    "    except wikipedia.DisambiguationError as e:\n",
    "        options = e.options\n",
    "        return len(options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a686483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mete\\anaconda3\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file C:\\Users\\mete\\anaconda3\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    }
   ],
   "source": [
    "print(get_len_disambiguation_options('plant (disambiguation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70c1280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def WIKI(title, num_of_meaning=None):\n",
    "    try:\n",
    "        wiki = wikipedia.page(title)\n",
    "        text = wiki.content\n",
    "        return text\n",
    "    except wikipedia.DisambiguationError as e:\n",
    "        options = e.options\n",
    "        if num_of_meaning is None:\n",
    "            while True:\n",
    "                choice = input(\"Enter the number of the desired option: \")\n",
    "                if choice.isdigit():\n",
    "                    choice = int(choice)\n",
    "                    if 1 <= choice <= len(options):\n",
    "                        selected_option = options[choice - 1]\n",
    "                        try:\n",
    "                            wiki = wikipedia.page(selected_option)\n",
    "                            text = wiki.content\n",
    "                            return text\n",
    "                        except wikipedia.DisambiguationError:\n",
    "                            print(f\"Sorry, '{selected_option}' is also a disambiguation page.\")\n",
    "                        except wikipedia.exceptions.PageError:\n",
    "                            print(f\"Page id for '{selected_option}' does not match any pages.\")\n",
    "                    else:\n",
    "                        print(\"Invalid option number. Please try again.\")\n",
    "                else:\n",
    "                    print(\"Invalid input. Please enter a valid number.\")\n",
    "        else:\n",
    "            if 1 <= num_of_meaning <= len(options):\n",
    "                selected_option = options[num_of_meaning - 1]\n",
    "                try:\n",
    "                    wiki = wikipedia.page(selected_option)\n",
    "                    text = wiki.content\n",
    "                    return text\n",
    "                except wikipedia.DisambiguationError:\n",
    "                    print(f\"Sorry, '{selected_option}' is also a disambiguation page.\")\n",
    "                except wikipedia.exceptions.PageError:\n",
    "                    print(f\"Page id for '{selected_option}' does not match any pages.\")\n",
    "            else:\n",
    "                raise ValueError('Invalid num_of_meaning input.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b266f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def WIKI_entities(title, num_of_meaning=None):\n",
    "    try:\n",
    "        wiki = wikipedia.page(title)\n",
    "        text = wiki.content\n",
    "        return text\n",
    "    except wikipedia.DisambiguationError as e:\n",
    "        options = e.options\n",
    "        return options\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5da1bc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C.a.R.',\n",
       " 'CAR and CDR',\n",
       " 'Clock with Adaptive Replacement',\n",
       " 'Computer-assisted reporting',\n",
       " 'Computer-assisted reviewing',\n",
       " 'Capital adequacy ratio',\n",
       " 'Cost accrual ratio',\n",
       " 'Cumulative abnormal return',\n",
       " 'Cumulative average return',\n",
       " 'Cars (franchise)',\n",
       " 'Cars (film)',\n",
       " 'The Car (1977 film)',\n",
       " \"BBC Two '1991â€“2001' idents\",\n",
       " 'The Car (1997 film)',\n",
       " '\"The Car\" (The Assistants episode)',\n",
       " 'Car (magazine)',\n",
       " 'The Car (novel)',\n",
       " 'Canadian Airborne Regiment',\n",
       " 'Colt Automatic Rifle',\n",
       " 'Combat Action Ribbon',\n",
       " 'U.S. Army Combat Arms Regimental System',\n",
       " 'Conflict Armament Research',\n",
       " 'The Cars',\n",
       " 'Peter Gabriel (1977 album)',\n",
       " 'The Cars (album)',\n",
       " 'Cars (soundtrack)',\n",
       " 'Cars (Now, Now Every Children album)',\n",
       " 'Kris Delmhorst',\n",
       " 'C.A.R. (album)',\n",
       " 'The Car (album)',\n",
       " '\"The Car\" (song)',\n",
       " '\"Cars\" (song)',\n",
       " \"There's Nothing Wrong with Love\",\n",
       " 'Cars (painting)',\n",
       " 'The Car (Brack)',\n",
       " 'Car (surname)',\n",
       " 'Cars (surname)',\n",
       " 'Car, Azerbaijan',\n",
       " 'ÄŒar',\n",
       " 'Cars, Gironde',\n",
       " 'Les Cars',\n",
       " 'Central African Republic',\n",
       " 'Central Asian Republics',\n",
       " 'Cordillera Administrative Region',\n",
       " 'County Carlow',\n",
       " 'Canonical anticommutation relation',\n",
       " 'Carina (constellation)',\n",
       " 'Chimeric antigen receptor',\n",
       " 'Coherent anti-Stokes Raman spectroscopy',\n",
       " 'Constitutive androstane receptor',\n",
       " 'Cortisol awakening response',\n",
       " 'Coxsackievirus and adenovirus receptor',\n",
       " 'Carolina Hurricanes',\n",
       " 'Carolina Panthers',\n",
       " 'Club Always Ready',\n",
       " 'Rugby Africa',\n",
       " 'Railroad car',\n",
       " 'Canada Atlantic Railway',\n",
       " 'Canadian Atlantic Railway',\n",
       " \"Carlisle railway station's\",\n",
       " 'elevator',\n",
       " 'tram',\n",
       " 'Car (Greek myth)',\n",
       " 'Car language',\n",
       " 'Carib language',\n",
       " 'Cars (video game)',\n",
       " 'Chimeric antigen receptor',\n",
       " 'Canadian Aviation Regulations',\n",
       " 'Avis Budget Group',\n",
       " 'Central apparatus room',\n",
       " 'Children of the American Revolution',\n",
       " \"ComitÃ© d'Action pour la Renouveau\",\n",
       " 'Reconciliation in Australia',\n",
       " 'Council for Aboriginal Rights',\n",
       " 'Criminal Appeal Reports',\n",
       " 'All pages with titles beginning with Car',\n",
       " 'All pages with titles containing Car',\n",
       " 'Carr (disambiguation)',\n",
       " 'CARS (disambiguation)',\n",
       " 'Le Car (disambiguation)',\n",
       " 'iCar',\n",
       " 'All pages with titles containing Car',\n",
       " 'All pages with titles beginning with Car']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WIKI_entities('Car (disambiguation)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37fbb6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset: plant.n.01\n",
      "Definition: buildings for carrying on industrial labor\n",
      "POS (Part of Speech): n\n",
      "Examples: ['they built a large plant to manufacture automobiles']\n",
      "\n",
      "Synset: plant.n.02\n",
      "Definition: (botany) a living organism lacking the power of locomotion\n",
      "POS (Part of Speech): n\n",
      "Examples: []\n",
      "\n",
      "Synset: plant.n.03\n",
      "Definition: an actor situated in the audience whose acting is rehearsed but seems spontaneous to the audience\n",
      "POS (Part of Speech): n\n",
      "Examples: []\n",
      "\n",
      "Synset: plant.n.04\n",
      "Definition: something planted secretly for discovery by another\n",
      "POS (Part of Speech): n\n",
      "Examples: ['the police used a plant to trick the thieves', 'he claimed that the evidence against him was a plant']\n",
      "\n",
      "Synset: plant.v.01\n",
      "Definition: put or set (seeds, seedlings, or plants) into the ground\n",
      "POS (Part of Speech): v\n",
      "Examples: [\"Let's plant flowers in the garden\"]\n",
      "\n",
      "Synset: implant.v.01\n",
      "Definition: fix or set securely or deeply\n",
      "POS (Part of Speech): v\n",
      "Examples: ['He planted a knee in the back of his opponent', 'The dentist implanted a tooth in the gum']\n",
      "\n",
      "Synset: establish.v.02\n",
      "Definition: set up or lay the groundwork for\n",
      "POS (Part of Speech): v\n",
      "Examples: ['establish a new department']\n",
      "\n",
      "Synset: plant.v.04\n",
      "Definition: place into a river\n",
      "POS (Part of Speech): v\n",
      "Examples: ['plant fish']\n",
      "\n",
      "Synset: plant.v.05\n",
      "Definition: place something or someone in a certain position in order to secretly observe or deceive\n",
      "POS (Part of Speech): v\n",
      "Examples: ['Plant a spy in Moscow', \"plant bugs in the dissident's apartment\"]\n",
      "\n",
      "Synset: plant.v.06\n",
      "Definition: put firmly in the mind\n",
      "POS (Part of Speech): v\n",
      "Examples: [\"Plant a thought in the students' minds\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word = \"plant\"\n",
    "synsets = wn.synsets(word)\n",
    "definitions = []\n",
    "# Display the synsets\n",
    "for synset in synsets:\n",
    "    print(f\"Synset: {synset.name()}\")\n",
    "    print(f\"Definition: {synset.definition()}\")\n",
    "    print(f\"POS (Part of Speech): {synset.pos()}\")\n",
    "    print(f\"Examples: {synset.examples()}\\n\")\n",
    "    definitions.append(synset.definition())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "256ecd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buildings for carrying on industrial labor',\n",
       " '(botany) a living organism lacking the power of locomotion',\n",
       " 'an actor situated in the audience whose acting is rehearsed but seems spontaneous to the audience',\n",
       " 'something planted secretly for discovery by another',\n",
       " 'put or set (seeds, seedlings, or plants) into the ground',\n",
       " 'fix or set securely or deeply',\n",
       " 'set up or lay the groundwork for',\n",
       " 'place into a river',\n",
       " 'place something or someone in a certain position in order to secretly observe or deceive',\n",
       " 'put firmly in the mind']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb7dde5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plant', 'requires', 'sunlight', 'watering', 'every', 'morning']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1163c29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definition of the sense: put firmly in the mind\n",
      "Example sentence of the sense: Plant a thought in the students' minds\n"
     ]
    }
   ],
   "source": [
    "# Regular lesk algorithm using default Wordnet\n",
    "tokenized_sent\n",
    "sense = (lesk(tokenized_sent,target))\n",
    "print(f'Definition of the sense: {sense.definition()}')\n",
    "print(f'Example sentence of the sense: {sense.examples()[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b84a43f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manuel lesk alg for\n",
    "def lesk_alg2(sentence,definitions,target):\n",
    "    sentence = preprocess_wnlemma(sentence)\n",
    "    result = None\n",
    "    max_score = 0\n",
    "    matching_words = []\n",
    "    for definition in definitions:\n",
    "        score = 0\n",
    "        def_words = preprocess_wnlemma(definition)\n",
    "        useful_word_def = def_words.copy()\n",
    "        if target in useful_word_def:\n",
    "            useful_word_def.remove(target)\n",
    "        for word in sentence:\n",
    "            for use_word in useful_word_def:\n",
    "                if word == use_word:\n",
    "                    score += 1\n",
    "        score = score/len(def_words)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            result = definition\n",
    "    if max_score > 0:\n",
    "        return [matching_words, max_score, result]\n",
    "    else:\n",
    "        return max_score\n",
    "    \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67995c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesk_alg3(sentence, definitions, target):\n",
    "    sentence = preprocess_wnlemma(sentence)\n",
    "    sentence.remove(target)\n",
    "    result = None\n",
    "    max_score = 0\n",
    "    matching_words = []\n",
    "\n",
    "    for definition in definitions:\n",
    "        score = 0\n",
    "        def_words = preprocess_wnlemma(definition)\n",
    "        useful_word_def = def_words.copy()\n",
    "\n",
    "        if target in useful_word_def:\n",
    "            useful_word_def.remove(target)\n",
    "\n",
    "        for word in sentence:\n",
    "            for use_word in useful_word_def:\n",
    "                if word == use_word:\n",
    "                    score += 1\n",
    "\n",
    "        score = score / len(useful_word_def)\n",
    "\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            result = definition\n",
    "            matching_words = [word for word in sentence if word in def_words]\n",
    "\n",
    "    if max_score > 0:\n",
    "        return nltk.sent_tokenize(result)[0]\n",
    "    else:\n",
    "        return max_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b650c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesk_alg_with_window(sentence, definitions, target, window_size=10):\n",
    "    copy_sentence = sentence\n",
    "    sentence = preprocess_wnlemma(sentence)\n",
    "    sentence.remove(target)\n",
    "    result = None\n",
    "    max_score = 0\n",
    "    matching_words = []\n",
    "\n",
    "    for definition in definitions:\n",
    "        score = 0\n",
    "        def_words = preprocess_wnlemma(definition)\n",
    "        \n",
    "        target_indices = [i for i, word in enumerate(def_words) if word == target]\n",
    "        \n",
    "        for target_index in target_indices:\n",
    "            start = max(0, target_index - window_size)\n",
    "            end = min(len(def_words), target_index + window_size + 1)\n",
    "            \n",
    "            window_words = def_words[start:end]\n",
    "            \n",
    "            for word in sentence:\n",
    "                if word in window_words:\n",
    "                    score += 1\n",
    "            \n",
    "            score = score / len(window_words)\n",
    "\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                result = definition\n",
    "                matching_words = [word for word in sentence if word in window_words]\n",
    "\n",
    "    if max_score > 0:\n",
    "        return nltk.sent_tokenize(result)[0]\n",
    "    else:\n",
    "        return lesk_alg3(copy_sentence, definitions, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e9f1135",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'something planted secretly for discovery by another plant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b06ecfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_senses(target):\n",
    "    main_sense = Wiki_main(target)\n",
    "    other_senses = []\n",
    "    max_iterator = get_len_disambiguation_options(target + ' (disambiguation)')\n",
    "    i = 1\n",
    "    while i <= max_iterator:\n",
    "        sense = WIKI(target + ' (disambiguation)', i)\n",
    "        if sense is not None and len(sense) > 400:\n",
    "            sense = sense[:400]\n",
    "            other_senses.append(sense)\n",
    "        elif sense is not None:\n",
    "            other_senses.append(sense)\n",
    "        i += 1\n",
    "    other_senses.append(main_sense)\n",
    "    return other_senses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6059c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_senses2(target):\n",
    "    main_sense = WIKI_main(target)\n",
    "    other_senses = []\n",
    "    for entity in WIKI_entities(target +' (disambiguation)'):\n",
    "        other_sense = WIKI_main(entity)\n",
    "        other_senses.append(other_sense)\n",
    "    other_senses.append(main_sense)\n",
    "    return other_senses\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bcb85c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = wiki_senses2('bank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95308d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = wiki_senses2('plant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "833fe49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f6a5226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Plants are the eukaryotes that form the kingdom Plantae; they are predominantly photosynthetic.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesk_alg_with_window(S, t, 'plant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b74b48e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Bank is financial prison of the society.'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
